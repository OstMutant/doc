-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Big data (https://intellect.ml/big-data-chast-1-printsipy-raboty-s-bolshimi-dannymi-paradigma-mapreduce-6815)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	Большие данные (англ. big data) — серия подходов, инструментов и методов обработки структурированных и неструктурированных данных огромных объёмов
	 и значительного многообразия для получения воспринимаемых человеком результатов,
	 эффективных в условиях непрерывного прироста, распределения по многочисленным узлам вычислительной сети.
	 
		-- Принципы работы с большими данными
			1. Горизонтальная масштабируемость. Cистема, которая подразумевает обработку больших данных, должна быть расширяемой.
			2. Отказоустойчивость. Принцип горизонтальной масштабируемости подразумевает, что машин в кластере может быть много.
			3. Локальность данных. По возможности обрабатываем данные на той же машине, на которой их храним. 

	Кластер — группа компьютеров, объединённых высокоскоростными каналами связи, представляющая с точки зрения пользователя единый аппаратный ресурс. 
	Кластер - слабо связанная совокупность нескольких вычислительных систем, работающих совместно для выполнения общих приложений, и представляющихся пользователю единой системой.
	
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Hadoop Distributed File System (HDFS) (https://uk.wikipedia.org/wiki/Hadoop_Distributed_Filesystem)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
			
	Hadoop Distributed File System (HDFS) - це розподілена файлова система, яка забезпечує високошвидкісний доступ до даних і є одним з ключових компонентів платформи Hadoop. 
	HDFS - це файлова система на основі Java, яка забезпечує масштабуємість і надійне зберігання даних, призначена для розбиття великих кластерів на стандартних серверах. 
	HDFS, MapReduce та YARN утворюють ядро Apache Hadoop.
	
	HDFS є ієрархічною файловою системою. Таким чином, в HDFS є підтримка вкладення каталогів. У каталозі може розташовуватися нуль або більше файлів, а також будь-яка кількість підкаталогів.
	HDFS складається з наступних обов'язкових компонентів:
		Вузол імен (NameNode) - програмний код, що виконується, в загальному випадку, на виділеній машині примірника HDFS і відповідає за файлові операції (роботу з метаданими);
			- управління простором імен файлової системи
			- управління доступом з боку зовнішніх клієнтів
			- відповідність між файлами і реплицироваться на вузлах даних блоками
		Вузол даних (DataNode) - програмний код, як правило, виконується виділеної машині примірника HDFS і відповідає за операції рівня файлу (робота з блоками даних).
			- періодичну відправку повідомлення про стан (heartbeat-повідомлення)
			- обробку запитів на читання і запис, що надходять від клієнтів файлової системи HDFS
	
	Основні концепції, закладені при проектуванні HDFS
		Обсяг даних. HDFS не повинна мати досяжних в осяжному майбутньому обмежень на обсяг збережених даних.
		Відмовостійкість. HDFS розцінює вихід з ладу вузла даних як норму, а не як виняток (дійсно, ймовірність виходу хоча б одного вузла з тисячі навіть на надійному фізичному обладнанні істотна).
		Автодіагностика. Діагностика справності вузлів в Hadoop-кластері не повинна вимагати додаткового адміністрування.
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
MapReduce (https://intellect.ml/big-data-chast-1-printsipy-raboty-s-bolshimi-dannymi-paradigma-mapreduce-6815)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	MapReduce – это модель распределенной обработки данных, предложенная компанией Google для обработки больших объёмов данных на компьютерных кластерах.
	MapReduce предполагает, что данные организованы в виде некоторых записей. Обработка данных происходит в 3 стадии: 
		
		1. Стадия Map. На этой стадии данные предобрабатываются при помощи функции map(), которую определяет пользователь.
			Функция map() примененная к одной входной записи и выдаёт множество пар ключ-значение.

		2. Стадия Shuffle. Проходит незаметно для пользователя. В этой стадии вывод функции map «разбирается по корзинам» – каждая корзина соответствует одному ключу вывода стадии map. 
			В дальнейшем эти корзины послужат входом для reduce. 
		
		3. Стадия Reduce. Каждая «корзина» со значениями, сформированная на стадии shuffle, попадает на вход функции reduce(). 
			Функция reduce задаётся пользователем и вычисляет финальный результат для отдельной «корзины». 
			Множество всех значений, возвращённых функцией reduce(), является финальным результатом MapReduce-задачи. 
			
		Работа MapReduce состоит из двух шагов: Map и Reduce, названных так по аналогии с одноименными функциями высшего порядка, map и reduce.
			На Map-шаге происходит предварительная обработка входных данных. Для этого один из компьютеров (называемый главным узлом — master node) получает входные данные задачи,
				разделяет их на части и передает другим компьютерам (рабочим узлам — worker node) для предварительной обработки.
			На Reduce-шаге происходит свёртка предварительно обработанных данных.
				Главный узел получает ответы от рабочих узлов и на их основе формирует результат — решение задачи, которая изначально формулировалась.
		
	Несколько дополнительных фактов про MapReduce: 
		1) Все запуски функции map работают независимо и могут работать параллельно, в том числе на разных машинах кластера. 
		2) Все запуски функции reduce работают независимо и могут работать параллельно, в том числе на разных машинах кластера. 
		3) Shuffle внутри себя представляет параллельную сортировку, поэтому также может работать на разных машинах кластера. 
			Пункты 1-3 позволяют выполнить принцип горизонтальной масштабируемости. 
		4) Функция map, как правило, применяется на той же машине, на которой хранятся данные – это позволяет снизить передачу данных по сети (принцип локальности данных). 
		5) MapReduce – это всегда полное сканирование данных, никаких индексов нет. Это означает, что MapReduce плохо применим, когда ответ требуется очень быстро. 

		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
YARN (https://www.ibm.com/developerworks/ru/library/bd-yarn-intro/)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Apache Hadoop (https://uk.wikipedia.org/wiki/Apache_Hadoop)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
		
	Apache Hadoop — вільна програмна платформа і каркас для організації розподіленого зберігання і обробки наборів великих даних з використанням моделі програмування MapReduce,
		при якій завдання ділиться на багато дрібніших відособлених фрагментів, кожен з яких може бути запущений на окремому вузлі кластера, що складається з серійних комп'ютерів.
		Всі модулі в Hadoop спроектовані з врахуванням припущення, що злам апаратного забезпечення трапляється часто і це повинно автоматично враховуватись фреймворком.
	Основний фреймворк Apache Hadoop складається з наступних модулів:
		Hadoop Common — містить бібліотеки та утиліти потрібні іншим модулям Hadoop;
		Hadoop Distributed File System (HDFS) — розподілена файлова система, яка зберігає дані на звичайних машинах, надаючи дуже високу загальну пропускну здатність на кластері загалом;
		Hadoop YARN — платформа що відповідає за керування обчислювальними ресурсами в кластерах і їх використання для користувацьких завдань.
		Hadoop MapReduce — реалізація моделі програмування MapReduce для обробки великих об'ємів даних.
		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Apache Spark (https://ru.wikipedia.org/wiki/Apache_Spark)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

	Apache Spark (от англ. spark — искра, вспышка) — программный каркас с открытым исходным кодом для реализации распределённой обработки неструктурированных и слабоструктурированных данных,
		входящий в экосистему проектов Hadoop. В отличие от классического обработчика из ядра Hadoop, реализующего двухуровневую концепцию MapReduce с дисковым хранилищем,
		использует специализированные примитивы для рекурентной обработки в оперативной памяти, благодаря чему позволяет получать значительный выигрыш в скорости работы для некоторых классов задач,
		в частности, возможность многократного доступа к загруженным в память пользовательским данным делает библиотеку привлекательной для алгоритмов машинного обучения.
		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Hbase (https://intellect.ml/big-data-ot-chast-4-hbase-6819)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	Hbase — это распределенная, колоночно-ориентированная, мультиверсионная база типа «ключ-значение». 
	Данные организованы в таблицы, проиндексированные первичным ключом, который в Hbase называется RowKey.  
	Для каждого RowKey ключа может храниться неограниченны набор атрибутов (или колонок).  
	Колонки организованны в группы колонок, называемые Column Family. Как правило в одну Column Family объединяют колонки, для которых одинаковы паттерн использования и хранения.  
	Для каждого аттрибута может храниться несколько различных версий. Разные версии имеют разный timestamp. Записи физически хранятся в отсортированном по RowKey порядке. 
	При этом данные соответствующие разным Column Family хранятся отдельно, что позволяет при необходимости читать данные только из нужного семейства колонок.  
	При удалении определённого атрибута физически он сразу не удаляется, а лишь маркируется специальным флажком tombstone. Физическое удаление данных произойдет позже, при выполнении операции Major Compaction. 
	Атрибуты, принадлежащие одной группе колонок и соответствующие одному ключу физически хранятся как отсортированный список. 
	Любой атрибут может отсутствовать или присутствовать для каждого ключа, при этом если атрибут отсутствует — это не вызывает накладных расходов на хранение пустых значений. 
	Список и названия групп колонок фиксирован и имеет четкую схему. На уровне группы колонок задаются такие параметры как time to live (TTL) и максимальное количество хранимых версий. 
	Если разница между timestamp для определенно версии и текущим временем больше TTL — запись помечается к удалению. 
	Если количество версий для определённого атрибута превысило максимальное количество версий — запись также помечается к удалению.

	Поддерживаемые операции Список поддерживаемых операций в hbase весьма прост. Поддерживаются 4 основные операции: 
		— Put: добавить новую запись в hbase. Timestamp этой записи может быть задан руками, в противном случае он будет установлен автоматически как текущее время. 
		— Get: получить данные по определенному RowKey. Можно указать Column Family, из которой будем брать данные и количество версий которые хотим прочитать.  
		— Scan: читать записи по очереди. Можно указать запись с которой начинаем читать, запись до которой читать, количество записей которые необходимо считать, 
			Column Family из которой будет производиться чтение и максимальное количество версий для каждой записи.  
		— Delete: пометить определенную версию к удалению. Физического удаления при этом не произойдет, оно будет отложено до следующего Major Compaction
		
	Hbase для своей работы использует два основных процесса: 
		1. Region Server — обслуживает один или несколько регионов. Регион — это диапазон записей соответствующих определенному диапазону подряд идущих RowKey.
			Persistent Storage — основное хранилище данных в Hbase. Данные физически хранятся на HDFS, в специальном формате HFile. 
				Данные в HFile хранятся в отсортированном по RowKey порядке. Одной паре (регион, column family) соответствует как минимум один HFIle.
			MemStore — буфер на запись. Так как данные хранятся в HFile d отсортированном порядке — обновлять HFile на каждую запись довольно дорого. 
				Вместо этого данные при записи попадают в специальную область памяти MemStore, где накапливаются некоторое время. 
				При наполнении MemStore до некоторого критического значения данные записываются в новый HFile.
			BlockCache — кэш на чтение. Позволяет существенно экономить время на данных которые читаются часто.
			Write Ahead Log(WAL). Так как данные при записи попадают в memstore, существует некоторый риск потери данных из-за сбоя. 
				Для того чтобы этого не произошло все операции перед собственно осуществление манипуляций попадают в специальный лог-файл. 
				Это позволяет восстановить данные после любого сбоя.
		2. Master Server — главный сервер в кластере hbase. 
		Master управляет распределением регионов по Region Server’ам, ведет реестр регионов, управляет запусками регулярных задач и делает другую полезную работу. 
			Minor Compaction. Запускается автоматически, выполняется в фоновом режиме. Имеет низкий приоритет по сравнению с другими операциями Hbase. 
			Major Compaction. Запускается руками или по наступлению срабатыванию определенных триггеров(например по таймеру). 
				Имеет высокий приоритет и может существенно замедлить работу кластера. Major Compaction’ы лучше делать во время когда нагрузка на кластер небольшая. 
				Во время Major Compaction также происходит физическое удаление данных, ране помеченных меткой tombstone. 

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

-- ------------------------------------------------ Solr
Solr (произносится «солар»[1]) — платформа полнотекстового поиска с открытым исходным кодом, основанная на проекте Apache Lucene. 
Её основные возможности: полнотекстовый поиск, подсветка результатов, фасетный поиск, динамическая кластеризация, интеграция с базами данных, обработка документов со сложным форматом (например, Word, PDF). 
Так как в Solr есть возможность распределенного поиска и репликации, Solr хорошо масштабируем[2].


Первые версии программ полнотекстового поиска предполагали сканирование всего содержимого всех документов в поиске заданного слова или фразы. 
При использовании такой технологии поиск занимал очень много времени (в зависимости от размера базы), а в интернете был бы невыполним.
 Современные алгоритмы заранее формируют для поиска так называемый полнотекстовый индекс — словарь, в котором перечислены все слова и указано, в каких местах они встречаются. 
При наличии такого индекса достаточно осуществить поиск нужных слов в нём и тогда сразу же будет получен список документов, в которых они встречаются.




-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-- ------------------------------------------------ Фреймворк Apache Maven (http://java-online.ru/maven-pom.xhtml)
		Apache Maven предназначен для автоматизации процесса сборки проектов на основе описания их структуры в файле на языке POM (Project Object Model), который является подмножеством формата XML.
			maven позволяет выполнять компиляцию кодов, создавать дистрибутив программы, архивные файлы jar/war и генерировать документацию. Простые проекты maven может собрать в командной строке.
			
		Терминология maven
			В maven используется свой набор терминов и понятий. Ключевым понятием maven является артефакт (artifact) — это, по сути, любая библиотека, хранящаяся в репозитории, к которой можно отнести зависимость или плагин.
			Зависимости (dependencies) представляют собой библиотеки, которые непосредственно используются в проекте для компиляции или тестирования кода.
			При сборке проекта или для каких-то других целей (deploy, создание файлов проекта для Eclipse и др.) maven использует плагины (plugin).
			
-- ------------------------------------------------ ANTLR(https://github.com/antlr/antlr4/blob/master/doc/index.md, https://ru.wikipedia.org/wiki/ANTLR)
		ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files.
			It's widely used to build languages, tools, and frameworks. From a grammar, ANTLR generates a parser that can build and walk parse trees.