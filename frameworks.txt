-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Big data (https://intellect.ml/big-data-chast-1-printsipy-raboty-s-bolshimi-dannymi-paradigma-mapreduce-6815)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	Большие данные (англ. big data) — серия подходов, инструментов и методов обработки структурированных и неструктурированных данных огромных объёмов
	 и значительного многообразия для получения воспринимаемых человеком результатов,
	 эффективных в условиях непрерывного прироста, распределения по многочисленным узлам вычислительной сети.
	 
		-- Принципы работы с большими данными
			1. Горизонтальная масштабируемость. Cистема, которая подразумевает обработку больших данных, должна быть расширяемой.
			2. Отказоустойчивость. Принцип горизонтальной масштабируемости подразумевает, что машин в кластере может быть много.
			3. Локальность данных. По возможности обрабатываем данные на той же машине, на которой их храним. 

	Кластер — группа компьютеров, объединённых высокоскоростными каналами связи, представляющая с точки зрения пользователя единый аппаратный ресурс. 
	Кластер - слабо связанная совокупность нескольких вычислительных систем, работающих совместно для выполнения общих приложений, и представляющихся пользователю единой системой.
	
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Hadoop Distributed File System (HDFS) (https://uk.wikipedia.org/wiki/Hadoop_Distributed_Filesystem)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
			
	Hadoop Distributed File System (HDFS) - це розподілена файлова система, яка забезпечує високошвидкісний доступ до даних і є одним з ключових компонентів платформи Hadoop. 
	HDFS - це файлова система на основі Java, яка забезпечує масштабуємість і надійне зберігання даних, призначена для розбиття великих кластерів на стандартних серверах. 
	HDFS, MapReduce та YARN утворюють ядро Apache Hadoop.
	
	HDFS є ієрархічною файловою системою. Таким чином, в HDFS є підтримка вкладення каталогів. У каталозі може розташовуватися нуль або більше файлів, а також будь-яка кількість підкаталогів.
	HDFS складається з наступних обов'язкових компонентів:
		Вузол імен (NameNode) - програмний код, що виконується, в загальному випадку, на виділеній машині примірника HDFS і відповідає за файлові операції (роботу з метаданими);
			- управління простором імен файлової системи
			- управління доступом з боку зовнішніх клієнтів
			- відповідність між файлами і реплицироваться на вузлах даних блоками
		Вузол даних (DataNode) - програмний код, як правило, виконується виділеної машині примірника HDFS і відповідає за операції рівня файлу (робота з блоками даних).
			- періодичну відправку повідомлення про стан (heartbeat-повідомлення)
			- обробку запитів на читання і запис, що надходять від клієнтів файлової системи HDFS
	
	Основні концепції, закладені при проектуванні HDFS
		Обсяг даних. HDFS не повинна мати досяжних в осяжному майбутньому обмежень на обсяг збережених даних.
		Відмовостійкість. HDFS розцінює вихід з ладу вузла даних як норму, а не як виняток (дійсно, ймовірність виходу хоча б одного вузла з тисячі навіть на надійному фізичному обладнанні істотна).
		Автодіагностика. Діагностика справності вузлів в Hadoop-кластері не повинна вимагати додаткового адміністрування.
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
MapReduce (https://intellect.ml/big-data-chast-1-printsipy-raboty-s-bolshimi-dannymi-paradigma-mapreduce-6815)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	MapReduce – это модель распределенной обработки данных, предложенная компанией Google для обработки больших объёмов данных на компьютерных кластерах.
	MapReduce предполагает, что данные организованы в виде некоторых записей. Обработка данных происходит в 3 стадии: 
		
		1. Стадия Map. На этой стадии данные предобрабатываются при помощи функции map(), которую определяет пользователь.
			Функция map() примененная к одной входной записи и выдаёт множество пар ключ-значение.

		2. Стадия Shuffle. Проходит незаметно для пользователя. В этой стадии вывод функции map «разбирается по корзинам» – каждая корзина соответствует одному ключу вывода стадии map. 
			В дальнейшем эти корзины послужат входом для reduce. 
		
		3. Стадия Reduce. Каждая «корзина» со значениями, сформированная на стадии shuffle, попадает на вход функции reduce(). 
			Функция reduce задаётся пользователем и вычисляет финальный результат для отдельной «корзины». 
			Множество всех значений, возвращённых функцией reduce(), является финальным результатом MapReduce-задачи. 
			
		Работа MapReduce состоит из двух шагов: Map и Reduce, названных так по аналогии с одноименными функциями высшего порядка, map и reduce.
			На Map-шаге происходит предварительная обработка входных данных. Для этого один из компьютеров (называемый главным узлом — master node) получает входные данные задачи,
				разделяет их на части и передает другим компьютерам (рабочим узлам — worker node) для предварительной обработки.
			На Reduce-шаге происходит свёртка предварительно обработанных данных.
				Главный узел получает ответы от рабочих узлов и на их основе формирует результат — решение задачи, которая изначально формулировалась.
		
	Несколько дополнительных фактов про MapReduce: 
		1) Все запуски функции map работают независимо и могут работать параллельно, в том числе на разных машинах кластера. 
		2) Все запуски функции reduce работают независимо и могут работать параллельно, в том числе на разных машинах кластера. 
		3) Shuffle внутри себя представляет параллельную сортировку, поэтому также может работать на разных машинах кластера. 
			Пункты 1-3 позволяют выполнить принцип горизонтальной масштабируемости. 
		4) Функция map, как правило, применяется на той же машине, на которой хранятся данные – это позволяет снизить передачу данных по сети (принцип локальности данных). 
		5) MapReduce – это всегда полное сканирование данных, никаких индексов нет. Это означает, что MapReduce плохо применим, когда ответ требуется очень быстро. 

		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
YARN (https://www.ibm.com/developerworks/ru/library/bd-yarn-intro/)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Apache Hadoop (https://uk.wikipedia.org/wiki/Apache_Hadoop)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
		
	Apache Hadoop — вільна програмна платформа і каркас для організації розподіленого зберігання і обробки наборів великих даних з використанням моделі програмування MapReduce,
		при якій завдання ділиться на багато дрібніших відособлених фрагментів, кожен з яких може бути запущений на окремому вузлі кластера, що складається з серійних комп'ютерів.
		Всі модулі в Hadoop спроектовані з врахуванням припущення, що злам апаратного забезпечення трапляється часто і це повинно автоматично враховуватись фреймворком.
	Основний фреймворк Apache Hadoop складається з наступних модулів:
		Hadoop Common — містить бібліотеки та утиліти потрібні іншим модулям Hadoop;
		Hadoop Distributed File System (HDFS) — розподілена файлова система, яка зберігає дані на звичайних машинах, надаючи дуже високу загальну пропускну здатність на кластері загалом;
		Hadoop YARN — платформа що відповідає за керування обчислювальними ресурсами в кластерах і їх використання для користувацьких завдань.
		Hadoop MapReduce — реалізація моделі програмування MapReduce для обробки великих об'ємів даних.
		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Apache Spark (https://ru.wikipedia.org/wiki/Apache_Spark)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

	Apache Spark (от англ. spark — искра, вспышка) — программный каркас с открытым исходным кодом для реализации распределённой обработки неструктурированных и слабоструктурированных данных,
		входящий в экосистему проектов Hadoop. В отличие от классического обработчика из ядра Hadoop, реализующего двухуровневую концепцию MapReduce с дисковым хранилищем,
		использует специализированные примитивы для рекурентной обработки в оперативной памяти, благодаря чему позволяет получать значительный выигрыш в скорости работы для некоторых классов задач,
		в частности, возможность многократного доступа к загруженным в память пользовательским данным делает библиотеку привлекательной для алгоритмов машинного обучения.
		
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Hbase (https://intellect.ml/big-data-ot-chast-4-hbase-6819)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
	Hbase — это распределенная, колоночно-ориентированная, мультиверсионная база типа «ключ-значение». 
	Данные организованы в таблицы, проиндексированные первичным ключом, который в Hbase называется RowKey.  
	Для каждого RowKey ключа может храниться неограниченны набор атрибутов (или колонок).  
	Колонки организованны в группы колонок, называемые Column Family. Как правило в одну Column Family объединяют колонки, для которых одинаковы паттерн использования и хранения.  
	Для каждого аттрибута может храниться несколько различных версий. Разные версии имеют разный timestamp. Записи физически хранятся в отсортированном по RowKey порядке. 
	При этом данные соответствующие разным Column Family хранятся отдельно, что позволяет при необходимости читать данные только из нужного семейства колонок.  
	При удалении определённого атрибута физически он сразу не удаляется, а лишь маркируется специальным флажком tombstone. Физическое удаление данных произойдет позже, при выполнении операции Major Compaction. 
	Атрибуты, принадлежащие одной группе колонок и соответствующие одному ключу физически хранятся как отсортированный список. 
	Любой атрибут может отсутствовать или присутствовать для каждого ключа, при этом если атрибут отсутствует — это не вызывает накладных расходов на хранение пустых значений. 
	Список и названия групп колонок фиксирован и имеет четкую схему. На уровне группы колонок задаются такие параметры как time to live (TTL) и максимальное количество хранимых версий. 
	Если разница между timestamp для определенно версии и текущим временем больше TTL — запись помечается к удалению. 
	Если количество версий для определённого атрибута превысило максимальное количество версий — запись также помечается к удалению.

	Поддерживаемые операции Список поддерживаемых операций в hbase весьма прост. Поддерживаются 4 основные операции: 
		— Put: добавить новую запись в hbase. Timestamp этой записи может быть задан руками, в противном случае он будет установлен автоматически как текущее время. 
		— Get: получить данные по определенному RowKey. Можно указать Column Family, из которой будем брать данные и количество версий которые хотим прочитать.  
		— Scan: читать записи по очереди. Можно указать запись с которой начинаем читать, запись до которой читать, количество записей которые необходимо считать, 
			Column Family из которой будет производиться чтение и максимальное количество версий для каждой записи.  
		— Delete: пометить определенную версию к удалению. Физического удаления при этом не произойдет, оно будет отложено до следующего Major Compaction
		
	Hbase для своей работы использует два основных процесса: 
		1. Region Server — обслуживает один или несколько регионов. Регион — это диапазон записей соответствующих определенному диапазону подряд идущих RowKey.
			Persistent Storage — основное хранилище данных в Hbase. Данные физически хранятся на HDFS, в специальном формате HFile. 
				Данные в HFile хранятся в отсортированном по RowKey порядке. Одной паре (регион, column family) соответствует как минимум один HFIle.
			MemStore — буфер на запись. Так как данные хранятся в HFile d отсортированном порядке — обновлять HFile на каждую запись довольно дорого. 
				Вместо этого данные при записи попадают в специальную область памяти MemStore, где накапливаются некоторое время. 
				При наполнении MemStore до некоторого критического значения данные записываются в новый HFile.
			BlockCache — кэш на чтение. Позволяет существенно экономить время на данных которые читаются часто.
			Write Ahead Log(WAL). Так как данные при записи попадают в memstore, существует некоторый риск потери данных из-за сбоя. 
				Для того чтобы этого не произошло все операции перед собственно осуществление манипуляций попадают в специальный лог-файл. 
				Это позволяет восстановить данные после любого сбоя.
		2. Master Server — главный сервер в кластере hbase. 
		Master управляет распределением регионов по Region Server’ам, ведет реестр регионов, управляет запусками регулярных задач и делает другую полезную работу. 
			Minor Compaction. Запускается автоматически, выполняется в фоновом режиме. Имеет низкий приоритет по сравнению с другими операциями Hbase. 
			Major Compaction. Запускается руками или по наступлению срабатыванию определенных триггеров(например по таймеру). 
				Имеет высокий приоритет и может существенно замедлить работу кластера. Major Compaction’ы лучше делать во время когда нагрузка на кластер небольшая. 
				Во время Major Compaction также происходит физическое удаление данных, ране помеченных меткой tombstone. 

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

-- ------------------------------------------------ Solr
Solr (произносится «солар»[1]) — платформа полнотекстового поиска с открытым исходным кодом, основанная на проекте Apache Lucene. 
Её основные возможности: полнотекстовый поиск, подсветка результатов, фасетный поиск, динамическая кластеризация, интеграция с базами данных, обработка документов со сложным форматом (например, Word, PDF). 
Так как в Solr есть возможность распределенного поиска и репликации, Solr хорошо масштабируем[2].


Первые версии программ полнотекстового поиска предполагали сканирование всего содержимого всех документов в поиске заданного слова или фразы. 
При использовании такой технологии поиск занимал очень много времени (в зависимости от размера базы), а в интернете был бы невыполним.
 Современные алгоритмы заранее формируют для поиска так называемый полнотекстовый индекс — словарь, в котором перечислены все слова и указано, в каких местах они встречаются. 
При наличии такого индекса достаточно осуществить поиск нужных слов в нём и тогда сразу же будет получен список документов, в которых они встречаются.




-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-- ------------------------------------------------ Фреймворк Apache Maven (http://java-online.ru/maven-pom.xhtml)
		Apache Maven предназначен для автоматизации процесса сборки проектов на основе описания их структуры в файле на языке POM (Project Object Model), который является подмножеством формата XML.
			maven позволяет выполнять компиляцию кодов, создавать дистрибутив программы, архивные файлы jar/war и генерировать документацию. Простые проекты maven может собрать в командной строке.
			
		Терминология maven
			В maven используется свой набор терминов и понятий. Ключевым понятием maven является артефакт (artifact) — это, по сути, любая библиотека, хранящаяся в репозитории, к которой можно отнести зависимость или плагин.
			Зависимости (dependencies) представляют собой библиотеки, которые непосредственно используются в проекте для компиляции или тестирования кода.
			При сборке проекта или для каких-то других целей (deploy, создание файлов проекта для Eclipse и др.) maven использует плагины (plugin).
	
		Maven Phases
		Although hardly a comprehensive list, these are the most common default lifecycle phases executed.
			validate: validate the project is correct and all necessary information is available
			compile: compile the source code of the project
			test: test the compiled source code using a suitable unit testing framework. These tests should not require the code be packaged or deployed
			package: take the compiled code and package it in its distributable format, such as a JAR.
			integration-test: process and deploy the package if necessary into an environment where integration tests can be run
			verify: run any checks to verify the package is valid and meets quality criteria
			install: install the package into the local repository, for use as a dependency in other projects locally
			deploy: done in an integration or release environment, copies the final package to the remote repository for sharing with other developers and projects.
		There are two other Maven lifecycles of note beyond the default list above. They are
			clean: cleans up artifacts created by prior builds
			site: generates site documentation for this project
	
-- ------------------------------------------------ ANTLR(https://github.com/antlr/antlr4/blob/master/doc/index.md, https://ru.wikipedia.org/wiki/ANTLR)
		ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files.
			It's widely used to build languages, tools, and frameworks. From a grammar, ANTLR generates a parser that can build and walk parse trees.

			
			
			
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Cloud (https://en.wikipedia.org/wiki/Cloud_computing)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
		Cloud computing is an information technology (IT) paradigm that enables ubiquitous access to shared pools of configurable system resources
			and higher-level services that can be rapidly provisioned with minimal management effort, often over the Internet.
		
-- ------------------------------------------------ Service models
		Software as a service (SaaS)
			The capability provided to the consumer is to use the provider's applications running on a cloud infrastructure. 
			The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. 
			The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities,
				with the possible exception of limited user-specific application configuration settings.
		Platform as a service (PaaS)
			The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services,
				and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage,
				but has control over the deployed applications and possibly configuration settings for the application-hosting environment.
		Infrastructure as a service (IaaS)
			"Infrastructure as a service" (IaaS) refers to online services that provide high-level APIs used to dereference various low-level details of underlying network infrastructure like physical computing resources,
				location, data partitioning, scaling, security, backup etc.
				
-- ------------------------------------------------ Deployment models
		Private cloud
			Private cloud is cloud infrastructure operated solely for a single organization, whether managed internally or by a third-party, and hosted either internally or externally.
		Public cloud
			A cloud is called a "public cloud" when the services are rendered over a network that is open for public use. Public cloud services may be free.
		Hybrid cloud
			Hybrid cloud is a composition of two or more clouds (private, community or public) that remain distinct entities but are bound together, offering the benefits of multiple deployment models.
			
-- ------------------------------------------------ Amazon Web Services (AWS)(https://en.wikipedia.org/wiki/Amazon_Web_Services)
		Amazon Web Services (AWS) is a subsidiary of Amazon.com that provides on-demand cloud computing platforms to individuals, companies and governments, on a paid subscription basis. 
			The technology allows subscribers to have at their disposal a full-fledged virtual cluster of computers, available all the time, through the Internet. 
			AWS's version of virtual computers have most of the attributes of a real computer including hardware (CPU(s) & GPU(s) for processing, local/RAM memory, hard-disk/SSD storage); 
			a choice of operating systems; networking; and pre-loaded application software such as web servers, databases, CRM, etc. 
			Each AWS system also virtualizes its console I/O (keyboard, display, and mouse), allowing AWS subscribers to connect to their AWS system using a modern browser.
			
-- ------------------------------------------------ Amazon EC2
		Amazon Elastic Compute Cloud (Amazon EC2)(https://aws.amazon.com/ru/ec2/?p=tile) – это веб-сервис, предоставляющий безопасные масштабируемые вычислительные ресурсы в облаке. 
			Он помогает разработчикам, облегчая проведение крупномасштабных вычислений в облаке.
		Amazon Elastic Compute Cloud (Amazon EC2)(https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html) provides scalable computing capacity in the Amazon Web Services (AWS) cloud.
			Amazon EC2 provides the following features:
				Virtual computing environments, known as instances
				Preconfigured templates for your instances, known as Amazon Machine Images (AMIs), that package the bits you need for your server (including the operating system and additional software)
				Various configurations of CPU, memory, storage, and networking capacity for your instances, known as instance types
				Secure login information for your instances using key pairs (AWS stores the public key, and you store the private key in a secure place)
				Storage volumes for temporary data that's deleted when you stop or terminate your instance, known as instance store volumes
				Persistent storage volumes for your data using Amazon Elastic Block Store (Amazon EBS), known as Amazon EBS volumes
				Multiple physical locations for your resources, such as instances and Amazon EBS volumes, known as regions and Availability Zones
				A firewall that enables you to specify the protocols, ports, and source IP ranges that can reach your instances using security groups
				Static IPv4 addresses for dynamic cloud computing, known as Elastic IP addresses
				Metadata, known as tags, that you can create and assign to your Amazon EC2 resources
				Virtual networks you can create that are logically isolated from the rest of the AWS cloud, and that you can optionally connect to your own network, known as virtual private clouds (VPCs)
		
		Elastic Load Balancing(https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html)
		Elastic Load Balancing distributes incoming application traffic across multiple EC2 instances, in multiple Availability Zones. This increases the fault tolerance of your applications.	
-- ------------------------------------------------ AWS Lambda
		AWS Lambda(https://aws.amazon.com/ru/lambda/?p=tile) позволяет запускать программные коды без выделения серверов и управления ими. Вы платите только за фактическое время вычисления. 
			Когда программы не выполняются, оплата не требуется.
		AWS Lambda (https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) is a compute service that lets you run code without provisioning or managing servers. 
			AWS Lambda executes your code only when needed and scales automatically, from a few requests per day to thousands per second. 
			You pay only for the compute time you consume - there is no charge when your code is not running. 
		Java Lambda API (https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/index.html?com/amazonaws/services/lambda/AWSLambda.html)
		Starting(https://aws.amazon.com/ru/lambda/?nc2=h_m1, https://aws.amazon.com/ru/lambda/resources/#Getting_Started)
		
-- ------------------------------------------------ Amazon API Gateway
		Amazon API Gateway(https://aws.amazon.com/ru/api-gateway/) – это полностью управляемый сервис для разработчиков, предназначенный для создания, публикации, обслуживания,
			мониторинга и обеспечения безопасности API в любых масштабах.
		
		Amazon API Gateway(https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html) is an AWS service that enables developers to create, publish, maintain, monitor, and secure APIs at any scale. 
			You can create APIs that access AWS or other web services, as well as data stored in the AWS Cloud.
			API Gateway can be considered a backplane in the cloud to connect AWS services and other public or private websites. 
			It provides consistent RESTful application programming interfaces (APIs) for mobile and web applications to access AWS services.
-- ------------------------------------------------ Amazon CloudWatch
		Amazon CloudWatch(https://aws.amazon.com/ru/cloudwatch/?p=tile) – это сервис мониторинга облачных ресурсов AWS и приложений, которые вы запускаете с их помощью. 
			Amazon CloudWatch можно использовать для сбора и отслеживания метрик, накопления и анализа файлов журналов, создания предупреждений, а также автоматического реагирования на изменения ресурсов AWS. 
-- ------------------------------------------------Amazon ElastiCach
		Amazon ElastiCache(https://aws.amazon.com/ru/elasticache/details/) – это веб-сервис, упрощающий развертывание и масштабирование в облаке хранилища или кэша в памяти, а также управление ими.
		Amazon ElastiCache(https://aws.amazon.com/ru/elasticache/?nc2=h_m1) поддерживает два сервиса с открытым исходным кодом для размещения данных в памяти.
			Redis – быстрое хранилище данных и кэш в памяти с открытым исходным кодом. 
				Amazon ElastiCache для Redis – это совместимый с Redis сервис хранения и кэширования данных в памяти, который обеспечивает простоту использования и функциональность Redis,
					а также доступность, надежность, масштабируемость и производительность, подходящие для самых требовательных приложений.
			Redis(https://aws.amazon.com/ru/elasticache/what-is-redis/) – быстрое хранилище в памяти с открытым исходным кодом для структур данных «ключ-значение». 
				Redis поставляется с набором разнообразных структур данных в памяти, что упрощает создание различных специальных приложений. 
			Memcached – широко распространенная система кэширования объектов в памяти. 
				Используемые в ElastiCache протоколы полностью совместимы с Memcached, поэтому все популярные инструменты, уже используемые в существующих средах Memcached, будут эффективно работать с этим сервисом.
-- ------------------------------------------------Amazon S3
		Amazon S3(https://aws.amazon.com/ru/s3/?p=tile) – это объектное хранилище, предназначенное для хранения и извлечения любых объемов данных из любых источников: веб-сайтов и мобильных приложений,
			корпоративных приложений, а также данных с датчиков или устройств IoT. 
-- ------------------------------------------------Amazon RDS
		Amazon Relational Database Service (Amazon RDS)(https://aws.amazon.com/ru/rds/details/) позволяет легко настраивать, использовать и масштабировать реляционные базы данных в облаке.


			
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	
Terraform(https://www.terraform.io/intro/index.html)
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
		Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions.
		
		